# Hadoop Diário
Hadoop diário são algumas notas de aprendizado sobre Apache Hadoop na Fatec Americana.

#### Etapas de desenvolvimento dos [projetos](https://github.com/z4r4tu5tr4/Hadoop-diario/tree/master/Projetos)
	
1. Drummond (Nov-Dez/2014) - Tentativa de encontrar padrões em textos de [Carlos Drummond de Andrade](https://pt.wikipedia.org/wiki/Carlos_Drummond_de_Andrade), tanto para aplicações de testes para Linguística, quanto de criptografia

2. Metereologia (Jan-Abr/2015) - Projeto com objetivo executar o cruzamento de dados dispostos pela [ESALQ-USP](http://www4.esalq.usp.br/)

3. Linguística de Corpus (Mai-Nov/2015) - Uma alternativa livre, usando o modelo MapReduce, para funções encontradas no [WordSmith Tools](http://www.lexically.net/wordsmith/)

#### Se você deseja aprender como instalar e configurar o Apache Hadoop

[instalação](https://github.com/z4r4tu5tr4/Hadoop-diario/tree/master/Instalacao)

#### Para facilitar sua vida usando Python e Hadoop, você pode usar a MapReduceLib:

[MapReduceLib](https://github.com/z4r4tu5tr4/MapReduceLib)


#### Sobre este diretório

Ele nasceu com objetivo de aprender e ensinar Apache hadoop a todos os interessados e com algumas prioridades:

	1. Fazer com que o aprendizado de hadoop seja acessivel a todos os não falantes de inglês ou de Javanes
	2. Propagar o uso de Software Livre
	3. Usar Python o máximo possível
	4. Resolver alguns problemas de linguistica de corpus
	5. Resolver alguns problemas metereológicos

#### Tempo de resposta do Hadoop [cluster](https://github.com/z4r4tu5tr4/Hadoop-diario/blob/master/cluster.md)

| Tamanho | Tempo em 1 nó |Tempo Cluster|
|--------|---------------|--------------|
|138 B |0.032s |4.274s|
|1.6 KB |0.034s| 4.182s|
|15.2 KB |0.063s| 5.165s|
|154.3 KB| 0.243s| 5.201s|
|1.5 MB |1.716s| 7.259s|
|15.3 MB |16.581s| 27.372s|
|153.4 MB| 2m 44.602s| 3m 53.429s|
|1.5 GB |33m 28.294s| 26m 43.265s|
|15.3 GB| 355m 1.318s| 97m 56.008s|
